{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GaussianNoise\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import vis_utils as vizu\n",
    "from keras.layers import Dropout\n",
    "from keras import callbacks\n",
    "from keras import backend\n",
    "from scipy.integrate import simps\n",
    "from scipy.stats import f\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    ssres = np.sum(np.square(y_true - y_pred))\n",
    "    sstot = np.sum(np.square(y_true - np.mean(y_pred)))\n",
    "    return 1 - ssres / sstot\n",
    "def REC(y_true , y_pred):   \n",
    "    Accuracy = []\n",
    "    Begin_Range = 0\n",
    "    End_Range = 1.5\n",
    "    Interval_Size = 0.01\n",
    "    \n",
    "    # List of epsilons\n",
    "    Epsilon = np.arange(Begin_Range , End_Range , Interval_Size)\n",
    "    \n",
    "    # Main Loops\n",
    "   \n",
    "    print(type(y_true))\n",
    "    for i in range(len(Epsilon)):\n",
    "        count = 0.0\n",
    "        for j in range(len(y_true)):\n",
    "\n",
    "            y_true[j]=float(y_true[j])\n",
    "           # print (y_true[j])\n",
    "\n",
    "         #   print(type(y_true[j]))\n",
    "    \n",
    "          #  print(type(y_pred[j]))\n",
    "\n",
    "\n",
    "            np.linalg.norm(y_true[j]- y_pred[j])\n",
    "\n",
    "            np.sqrt( np.linalg.norm(y_true[j]) **2 + np.linalg.norm(y_pred[j])**2 ) < Epsilon[i]\n",
    "            \n",
    "            if np.linalg.norm(y_true[j] - y_pred[j]) / np.sqrt( np.linalg.norm(y_true[j]) **2 + np.linalg.norm(y_pred[j])**2 ) < Epsilon[i]:\n",
    "                count = count + 1\n",
    "        \n",
    "        Accuracy.append(count/len(y_true))\n",
    "    \n",
    "    # Calculating Area Under Curve using Simpson's rule\n",
    "    AUC = simps(Accuracy , Epsilon ) / End_Range\n",
    "        \n",
    "    # returning epsilon , accuracy , area under curve    \n",
    "    return Epsilon, Accuracy, AUC\n",
    "\n",
    "def model_evaluate (model, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    Deviation, Accuracy, auc = REC(y_test.values, y_pred)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "    #r2 = r2_score(y_test, y_pred)\n",
    "    r2 = coeff_determination(y_test, y_pred)\n",
    "    mape = ((y_test - y_pred) / y_test).abs().mean()*100\n",
    "    \n",
    "    f_test = np.var(y_test) / np.var(y_pred)\n",
    "    df1 = len(y_test) - 1\n",
    "    df2 = len(y_pred) - 1\n",
    "    p_value = 1 - 2 * abs(0.5 - f.cdf(f_test, df1, df2))\n",
    "    \n",
    "    p_stars = ''\n",
    "    if p_value <= 0.05:\n",
    "        p_stars = '*'\n",
    "    if p_value <= 0.01:\n",
    "        p_stars = '**'\n",
    "    if p_value <= 0.001:\n",
    "        p_stars = '***'\n",
    "    #print(F, p_value)\n",
    "    \n",
    "    y_validate = model.predict(X_train)\n",
    "    training_loss = sqrt(mean_squared_error(y_train, y_validate))\n",
    "    \n",
    "    return_dict = {'rmse':rmse, \n",
    "                   'mape':mape, \n",
    "                   'r2':r2, \n",
    "                   'auc':auc,\n",
    "                   'training_loss':training_loss, \n",
    "                   'f_test':f_test,\n",
    "                   'p':p_stars,\n",
    "                   'y_pred':y_pred, \n",
    "                   'y_validate':y_validate}\n",
    "    \n",
    "    return return_dict\n",
    "\n",
    "def knn_baseline_model():\n",
    "    \n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #model.add(GaussianNoise(stddev=0.1, input_shape=(14,)))\n",
    "    model.add(Dense(7, activation='relu', input_shape=(17,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(GaussianNoise(0.1))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss=root_mean_squared_error, optimizer='adam')\n",
    "    #model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############\n",
    "\n",
    "\n",
    "conn = MongoClient('140.115.53.147', 27017)\n",
    "conn.database_names()\n",
    "db = conn['NCU_CHKA']\n",
    "\n",
    "\n",
    "collection = db['chka_final_score']\n",
    "final_score = pd.DataFrame(list(collection.find()))\n",
    "#final_score.to_csv('final_score.csv')\n",
    "collection = db['chka_all_features_by_week']\n",
    "all_features = pd.DataFrame(list(collection.find()))\n",
    "#all_features.to_csv('all_features.csv')\n",
    "\n",
    "\n",
    "all_features = all_features.drop(['_id'], axis=1)\n",
    "final_score = final_score.drop(['_id'], axis=1)\n",
    "\n",
    "#preprocessing\n",
    "mg=all_features.merge(final_score, on='username', how='left')\n",
    "mg = mg.drop(mg.columns[0], axis=1)\n",
    "\n",
    "mg = mg.drop(['username'], axis=1)\n",
    "\n",
    "#mg.to_csv('merge.csv')\n",
    "\n",
    "data = mg.query(\"week=='1'\")\n",
    "# 0 會出現 ZeroDivisionError\n",
    "data =data.query(\"final_score > '0' \")\n",
    "data.to_csv('data.csv')\n",
    "data_y= data['final_score']\n",
    "data_x = data.drop(['final_score'], axis=1)\n",
    "\n",
    "\n",
    "#print (data_y)\n",
    "#print (data_x)\n",
    "#data_y = data_y[0:15]\n",
    "#data_x=data_x [0:15]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.3)\n",
    "\n",
    "mlp = KerasRegressor(build_fn=knn_baseline_model, epochs=1000, batch_size=2, verbose=0)\n",
    "#print(X_train )\n",
    "#print(y_train)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "#mlp.fit(data_x, data_y)\n",
    "\n",
    "result_dict = model_evaluate (mlp, X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(result_dict)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
